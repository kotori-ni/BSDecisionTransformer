{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b904af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niworld\\AppData\\Local\\Temp\\ipykernel_19328\\1301542116.py:12: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.set_theme() \n",
    "\n",
    "import random\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3893e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather2power(weather, power_WT = 1000, power_PV = 1):\n",
    "    power_renergy = power_WT*weather[0] + power_PV*weather[1]\n",
    "    return power_renergy/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11896871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge2power(charge, pro):\n",
    "    if pro > (1-charge[0]-charge[1]):\n",
    "        power_charge = 0\n",
    "    else: \n",
    "        power_charge = 50\n",
    "    return power_charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4cab2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge2reward(charge, pro, error):\n",
    "    if pro > (1-charge[0]-charge[1]):\n",
    "        reward = 0\n",
    "    elif pro < charge[0]*error:\n",
    "        reward = 60\n",
    "    else:\n",
    "        reward = 100\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd1b23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traffic2power(traffic, traffic_max = 150):\n",
    "    power_BS = 2*traffic/traffic_max+2\n",
    "    return power_BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0086b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_RTP(T=31, train_flag=True):\n",
    "    if train_flag:\n",
    "        df = pd.read_table('../Data/RTP.csv', sep=\",\", nrows=24*T, skiprows=24*random.randint(0, 570))\n",
    "    else:\n",
    "        df = pd.read_table('../Data/RTP.csv', sep=\",\", nrows=24*T, skiprows=24*random.randint(600, 699))\n",
    "    df = df.to_numpy()\n",
    "    RTP = []\n",
    "    for data in df:        \n",
    "        RTP.append(float(data[1][data[1].find(\"$\")+1:]))\n",
    "    return RTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6346775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weather(T=31, train_flag=True):\n",
    "    if train_flag:\n",
    "        df = pd.read_table('../Data/weather.csv', sep=\",\", nrows= 24*T, skiprows=24*random.randint(0, 570))\n",
    "    else:\n",
    "        df = pd.read_table('../Data/weather.csv', sep=\",\", nrows= 24*T, skiprows=24*random.randint(600, 699))\n",
    "    df = df.to_numpy() \n",
    "    weather = []\n",
    "    for data in df:\n",
    "        data = data[1].split(\",\")\n",
    "        weather.append([float(data[-2]), float(data[-4])])\n",
    "    return weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68c5c581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape [192,1]\n",
    "def load_traffic(T=31, train_flag=True):\n",
    "    file = open(\"../Data/traffic\", \"rb\")\n",
    "    bytes_list = pickle.load(file)\n",
    "    bytes_list = np.r_[bytes_list, bytes_list, bytes_list, bytes_list]\n",
    "    return list(bytes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8fc55c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [incentive, always]\n",
    "def load_charge(T=31, train_flag=True):\n",
    "    file = open(\"../Data/charge\", \"rb\")\n",
    "    charge = pickle.load(file)\n",
    "    return charge.tolist()*31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7e7f9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load_charge())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aa14e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BS_EV():\n",
    "    def __init__(self, n_charge = 24, n_traffic=24, n_RTP = 24, n_weather = 24, train_flag = True, error=1.0):\n",
    "        #self.n_app = n_app\n",
    "        #self.n_actions = 2**n_app*3\n",
    "        self.n_states = n_RTP + 2*n_weather + n_traffic + 2*n_charge + 1 # RTP + weather + traffic + charge + SOC\n",
    "        self.n_traffic = n_traffic\n",
    "        self.n_actions = 3\n",
    "        self.RTP = []  # real time price\n",
    "        self.weather = [] # weather condition (WT, PV)\n",
    "        self.traffic = []\n",
    "        self.charge = []\n",
    "        self.SOC = 0  # percentage of SOC\n",
    "        self.n_RTP = n_RTP # length of RTP in state\n",
    "        self.n_weather = n_weather # length of weather in state\n",
    "        self.done = False # flag to illustrate the end of an episode\n",
    "        \n",
    "        self.T = 0 # time index\n",
    "\n",
    "        self.min_SOC = 0.2 # minimal SOC\n",
    "        self.SOC_charge_rate = 0.1 # charge rate of SOC\n",
    "        self.SOC_discharge_rate = 0.1 # discharge rate of SOC\n",
    "        self.SOC_per_cost = 0.01 # operation cost of each usage of ESS\n",
    "        self.SOC_eff = 1.1 # charge/discharge efficiency\n",
    "        self.AC_DC_eff = 1.1 # AC/DC conversion efficiency\n",
    "        self.ESS_cap = 500 # capacity of ESS\n",
    "        self.n_charge = n_charge # strata prediction of each time slot\n",
    "        self.train_flag = train_flag # train or test\n",
    "        self.error = error\n",
    "        \n",
    "    def reset(self):\n",
    "        self.SOC = random.uniform(self.min_SOC, 1) # reset SOC to a random percentage\n",
    "        self.T = 0\n",
    "        self.RTP = load_RTP(train_flag = self.train_flag)\n",
    "        self.weather = load_weather(train_flag = self.train_flag)\n",
    "        self.traffic = load_traffic()\n",
    "        self.charge = load_charge()\n",
    "        self.done = False\n",
    "        \n",
    "        observation = [self.RTP[self.T:self.T+self.n_RTP], self.weather[self.T:self.T+self.n_weather], self.traffic[self.T:self.T+self.n_traffic], self.charge[self.T:self.T+self.n_charge], [self.SOC]]\n",
    "        observation[1] = list(np.concatenate(observation[1]). flat)\n",
    "        observation[3] = list(np.concatenate(observation[3]). flat)\n",
    "        observation = list(np.concatenate(observation). flat)\n",
    "        return observation\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        action_SOC = action  # 0-not use; 1-charge; 2-discharge\n",
    "        \n",
    "        # check operation of SOC\n",
    "        if (self.SOC < self.min_SOC+self.SOC_discharge_rate and action_SOC == 2) or (self.SOC > 1-self.SOC_charge_rate and action_SOC == 1):\n",
    "            action_SOC = 0\n",
    "   \n",
    "        # ESS cost\n",
    "        SOC_cost = 0 if action_SOC == 0 else self.SOC_per_cost\n",
    "        \n",
    "        # power cost\n",
    "        pro = random.uniform(0, 1)\n",
    "        power_charge = charge2power(self.charge[self.T], pro)\n",
    "        power_BS = traffic2power(self.traffic[self.T])\n",
    "        power_renergy = weather2power(self.weather[self.T])# discharge power of renewable energy\n",
    "        \n",
    "        if action_SOC == 1: # ESS charge\n",
    "            self.SOC = self.SOC + self.SOC_charge_rate\n",
    "            power = max(power_BS*self.AC_DC_eff + power_charge + self.SOC_charge_rate*self.ESS_cap*self.SOC_eff - power_renergy, 0)\n",
    "        elif action_SOC == 2: # ESS discharge \n",
    "            self.SOC = self.SOC - self.SOC_discharge_rate\n",
    "            power = max(power_BS + power_charge - self.SOC_discharge_rate*self.ESS_cap*self.SOC_eff - power_renergy, 0)\n",
    "        else: # ESS not use\n",
    "            power = max(power_BS*self.AC_DC_eff + power_charge - power_renergy, 0)\n",
    "        # print(power_app, power_renergy)\n",
    "        power_cost = self.RTP[self.T]*power/100\n",
    "        # calculate reward\n",
    "        reward_charge = charge2reward(self.charge[self.T], pro, self.error)\n",
    "        reward = reward_charge - SOC_cost - power_cost\n",
    "        \n",
    "        self.T += 1\n",
    "        next_state = [self.RTP[self.T:self.T+self.n_RTP], self.weather[self.T:self.T+self.n_weather], self.traffic[self.T:self.T+self.n_traffic], self.charge[self.T:self.T+self.n_charge], [self.SOC]]\n",
    "        next_state[1] = list(np.concatenate(next_state[1]). flat)\n",
    "        next_state[3] = list(np.concatenate(next_state[3]). flat)\n",
    "        next_state = list(np.concatenate(next_state). flat)\n",
    "\n",
    "        if (self.T) % (24*30) == 0:\n",
    "            self.done = True\n",
    "        \n",
    "        return next_state, reward, self.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b190a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b70af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BS_EV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae7f179f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(23.97),\n",
       " np.float64(24.22),\n",
       " np.float64(24.7),\n",
       " np.float64(28.28),\n",
       " np.float64(32.08),\n",
       " np.float64(38.82),\n",
       " np.float64(22.29),\n",
       " np.float64(20.21),\n",
       " np.float64(19.68),\n",
       " np.float64(19.97),\n",
       " np.float64(21.3),\n",
       " np.float64(30.42),\n",
       " np.float64(34.94),\n",
       " np.float64(30.89),\n",
       " np.float64(35.28),\n",
       " np.float64(39.78),\n",
       " np.float64(47.41),\n",
       " np.float64(40.48),\n",
       " np.float64(40.6),\n",
       " np.float64(32.49),\n",
       " np.float64(29.73),\n",
       " np.float64(22.08),\n",
       " np.float64(22.55),\n",
       " np.float64(21.84),\n",
       " np.float64(0.30000000000000004),\n",
       " np.float64(0.0),\n",
       " np.float64(0.30000000000000004),\n",
       " np.float64(0.0),\n",
       " np.float64(0.30000000000000004),\n",
       " np.float64(0.0),\n",
       " np.float64(0.30000000000000004),\n",
       " np.float64(0.0),\n",
       " np.float64(0.4),\n",
       " np.float64(0.0),\n",
       " np.float64(0.4),\n",
       " np.float64(0.0),\n",
       " np.float64(0.4),\n",
       " np.float64(87.0),\n",
       " np.float64(0.5),\n",
       " np.float64(143.0),\n",
       " np.float64(0.5),\n",
       " np.float64(167.0),\n",
       " np.float64(0.5),\n",
       " np.float64(179.0),\n",
       " np.float64(0.5),\n",
       " np.float64(176.0),\n",
       " np.float64(0.5),\n",
       " np.float64(162.0),\n",
       " np.float64(0.5),\n",
       " np.float64(116.0),\n",
       " np.float64(0.5),\n",
       " np.float64(97.0),\n",
       " np.float64(0.4),\n",
       " np.float64(75.0),\n",
       " np.float64(0.4),\n",
       " np.float64(59.0),\n",
       " np.float64(0.5),\n",
       " np.float64(11.0),\n",
       " np.float64(0.5),\n",
       " np.float64(0.0),\n",
       " np.float64(0.5),\n",
       " np.float64(0.0),\n",
       " np.float64(0.5),\n",
       " np.float64(0.0),\n",
       " np.float64(0.5),\n",
       " np.float64(0.0),\n",
       " np.float64(0.4),\n",
       " np.float64(0.0),\n",
       " np.float64(0.30000000000000004),\n",
       " np.float64(0.0),\n",
       " np.float64(0.30000000000000004),\n",
       " np.float64(0.0),\n",
       " np.float64(71.039682958),\n",
       " np.float64(55.08355801),\n",
       " np.float64(36.089734111),\n",
       " np.float64(21.78059699),\n",
       " np.float64(11.133772528),\n",
       " np.float64(17.173212274),\n",
       " np.float64(47.620757366),\n",
       " np.float64(47.043260303),\n",
       " np.float64(53.745737059),\n",
       " np.float64(69.809501183),\n",
       " np.float64(72.558516473),\n",
       " np.float64(83.694070874),\n",
       " np.float64(92.392403153),\n",
       " np.float64(89.763946844),\n",
       " np.float64(78.565517152),\n",
       " np.float64(85.705226301),\n",
       " np.float64(108.735253831),\n",
       " np.float64(75.883798412),\n",
       " np.float64(84.658257284),\n",
       " np.float64(81.86422903),\n",
       " np.float64(101.786322971),\n",
       " np.float64(70.371672676),\n",
       " np.float64(75.017356512),\n",
       " np.float64(83.539649031),\n",
       " np.float64(0.26262471079826355),\n",
       " np.float64(0.40526142716407776),\n",
       " np.float64(0.005290942266583443),\n",
       " np.float64(0.4226222038269043),\n",
       " np.float64(0.012494316324591637),\n",
       " np.float64(0.3834874629974365),\n",
       " np.float64(0.22977666556835175),\n",
       " np.float64(0.3650895357131958),\n",
       " np.float64(0.20794470608234406),\n",
       " np.float64(0.2667101323604584),\n",
       " np.float64(0.0036887554451823235),\n",
       " np.float64(0.4908376932144165),\n",
       " np.float64(0.005205974914133549),\n",
       " np.float64(0.28716012835502625),\n",
       " np.float64(0.10428506135940552),\n",
       " np.float64(0.5020666122436523),\n",
       " np.float64(0.004069347400218248),\n",
       " np.float64(0.38131704926490784),\n",
       " np.float64(0.002488798927515745),\n",
       " np.float64(0.4547574818134308),\n",
       " np.float64(0.105807363986969),\n",
       " np.float64(0.43489742279052734),\n",
       " np.float64(0.3133888840675354),\n",
       " np.float64(0.4333949089050293),\n",
       " np.float64(0.14043591916561127),\n",
       " np.float64(0.49888691306114197),\n",
       " np.float64(0.0036249065306037664),\n",
       " np.float64(0.5520874261856079),\n",
       " np.float64(0.010157138109207153),\n",
       " np.float64(0.4662686586380005),\n",
       " np.float64(0.006472743581980467),\n",
       " np.float64(0.4793306291103363),\n",
       " np.float64(0.004194529727101326),\n",
       " np.float64(0.45617765188217163),\n",
       " np.float64(0.0011778065236285329),\n",
       " np.float64(0.36367636919021606),\n",
       " np.float64(0.0018547557992860675),\n",
       " np.float64(0.4665931165218353),\n",
       " np.float64(0.14277565479278564),\n",
       " np.float64(0.4785787761211395),\n",
       " np.float64(0.4167596101760864),\n",
       " np.float64(0.343463271856308),\n",
       " np.float64(0.7350466847419739),\n",
       " np.float64(0.0024267416447401047),\n",
       " np.float64(0.6879807710647583),\n",
       " np.float64(0.0028363314922899008),\n",
       " np.float64(0.7171862721443176),\n",
       " np.float64(0.002781118731945753),\n",
       " np.float64(0.24876605718121267)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d65a3e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state, reward, done = env.step(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a91520d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(47.94701289059286)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "93c3740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNetwork(nn.Module):\n",
    "    def __init__(self, n_actions, input_dims, alpha,\n",
    "            fc1_dims=256, fc2_dims=256, chkpt_dir='../tmp/'):\n",
    "        super(ActorNetwork, self).__init__()\n",
    "\n",
    "        self.checkpoint_file_best = os.path.join(chkpt_dir, 'actor_torch_ppo_best')\n",
    "        self.checkpoint_file_last = os.path.join(chkpt_dir, 'actor_torch_ppo_last')\n",
    "        self.actor = nn.Sequential(\n",
    "                nn.Linear(input_dims, fc1_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc2_dims, n_actions),\n",
    "                nn.Softmax(dim=-1)\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        #print(state)\n",
    "        dist = self.actor(state)\n",
    "        dist = Categorical(dist)\n",
    "        \n",
    "        return dist\n",
    "\n",
    "    def save_checkpoint_best(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file_best)\n",
    "        \n",
    "    def save_checkpoint_last(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file_last)\n",
    "\n",
    "    def load_checkpoint_best(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file_best))\n",
    "        \n",
    "    def load_checkpoint_last(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file_last))\n",
    "\n",
    "class CriticNetwork(nn.Module):\n",
    "    def __init__(self, input_dims, alpha, fc1_dims=256, fc2_dims=256,\n",
    "            chkpt_dir='../tmp/'):\n",
    "        super(CriticNetwork, self).__init__()\n",
    "\n",
    "        self.checkpoint_file_best = os.path.join(chkpt_dir, 'critic_torch_ppo_best')\n",
    "        self.checkpoint_file_last = os.path.join(chkpt_dir, 'critic_torch_ppo_last')\n",
    "        self.critic = nn.Sequential(\n",
    "                nn.Linear(input_dims, fc1_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc1_dims, fc2_dims),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(fc2_dims, 1)\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=alpha)\n",
    "        self.device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        value = self.critic(state)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def save_checkpoint_best(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file_best)\n",
    "        \n",
    "    def save_checkpoint_last(self):\n",
    "        T.save(self.state_dict(), self.checkpoint_file_last)\n",
    "\n",
    "    def load_checkpoint_best(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file_best))\n",
    "        \n",
    "    def load_checkpoint_last(self):\n",
    "        self.load_state_dict(T.load(self.checkpoint_file_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2e541ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOMemory:\n",
    "    def __init__(self, batch_size):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.vals = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def generate_batches(self):\n",
    "        n_states = len(self.states)\n",
    "        batch_start = np.arange(0, n_states, self.batch_size)\n",
    "        indices = np.arange(n_states, dtype=np.int64)\n",
    "        np.random.shuffle(indices)\n",
    "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
    "\n",
    "        return np.array(self.states),\\\n",
    "                np.array(self.actions),\\\n",
    "                np.array(self.probs),\\\n",
    "                np.array(self.vals),\\\n",
    "                np.array(self.rewards),\\\n",
    "                np.array(self.dones),\\\n",
    "                batches\n",
    "\n",
    "    def store_memory(self, state, action, probs, vals, reward, done):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.probs.append(probs)\n",
    "        self.vals.append(vals)\n",
    "        self.rewards.append(reward)\n",
    "        self.dones.append(done)\n",
    "\n",
    "    def clear_memory(self):\n",
    "        self.states = []\n",
    "        self.probs = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.dones = []\n",
    "        self.vals = []\n",
    "        \n",
    "class Agent:\n",
    "    def __init__(self, n_actions, input_dims, gamma=0.99, alpha=0.0003, gae_lambda=0.95,\n",
    "            policy_clip=0.2, batch_size=64, n_epochs=10):\n",
    "        self.gamma = gamma\n",
    "        self.policy_clip = policy_clip\n",
    "        self.n_epochs = n_epochs\n",
    "        self.gae_lambda = gae_lambda\n",
    "\n",
    "        self.actor = ActorNetwork(n_actions, input_dims, alpha)\n",
    "        self.critic = CriticNetwork(input_dims, alpha)\n",
    "        self.memory = PPOMemory(batch_size)\n",
    "       \n",
    "    def remember(self, state, action, probs, vals, reward, done):\n",
    "        self.memory.store_memory(state, action, probs, vals, reward, done)\n",
    "\n",
    "    def save_models_best(self):\n",
    "        print('... saving models ...')\n",
    "        self.actor.save_checkpoint_best()\n",
    "        self.critic.save_checkpoint_best()\n",
    "    \n",
    "    def save_models_last(self):\n",
    "        print('... saving models ...')\n",
    "        self.actor.save_checkpoint_last()\n",
    "        self.critic.save_checkpoint_last()\n",
    "\n",
    "    def load_models_best(self):\n",
    "        print('... loading models ...')\n",
    "        self.actor.load_checkpoint_best()\n",
    "        self.critic.load_checkpoint_best()\n",
    "        \n",
    "    def load_models_last(self):\n",
    "        print('... loading models ...')\n",
    "        self.actor.load_checkpoint_last()\n",
    "        self.critic.load_checkpoint_last()\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        state = T.tensor([observation], dtype=T.float32).to(self.actor.device)\n",
    "        dist = self.actor(state)\n",
    "        value = self.critic(state)\n",
    "        action = dist.sample()\n",
    "\n",
    "        probs = T.squeeze(dist.log_prob(action)).item()\n",
    "        action = T.squeeze(action).item()\n",
    "        value = T.squeeze(value).item()\n",
    "\n",
    "        return action, probs, value\n",
    "\n",
    "    def learn(self):\n",
    "        for _ in range(self.n_epochs):\n",
    "            state_arr, action_arr, old_prob_arr, vals_arr,\\\n",
    "            reward_arr, dones_arr, batches = \\\n",
    "                    self.memory.generate_batches()\n",
    "\n",
    "            values = vals_arr\n",
    "            advantage = np.zeros(len(reward_arr), dtype=np.float32)\n",
    "\n",
    "            for t in range(len(reward_arr)-1):\n",
    "                discount = 1\n",
    "                a_t = 0\n",
    "                for k in range(t, len(reward_arr)-1):\n",
    "                    a_t += discount*(reward_arr[k] + self.gamma*values[k+1]*\\\n",
    "                            (1-int(dones_arr[k])) - values[k])\n",
    "                    discount *= self.gamma*self.gae_lambda\n",
    "                advantage[t] = a_t\n",
    "            advantage = T.tensor(advantage,dtype=T.float32).to(self.actor.device)\n",
    "\n",
    "            values = T.tensor(values,dtype=T.float32).to(self.actor.device)\n",
    "            for batch in batches:\n",
    "                states = T.tensor(state_arr[batch], dtype=T.float32).to(self.actor.device)\n",
    "                old_probs = T.tensor(old_prob_arr[batch],dtype=T.float32).to(self.actor.device)\n",
    "                actions = T.tensor(action_arr[batch]).to(self.actor.device)\n",
    "\n",
    "                dist = self.actor(states)\n",
    "                critic_value = self.critic(states)\n",
    "\n",
    "                critic_value = T.squeeze(critic_value)\n",
    "\n",
    "                new_probs = dist.log_prob(actions)\n",
    "                prob_ratio = new_probs.exp() / old_probs.exp()\n",
    "                #prob_ratio = (new_probs - old_probs).exp()\n",
    "                weighted_probs = advantage[batch] * prob_ratio\n",
    "                weighted_clipped_probs = T.clamp(prob_ratio, 1-self.policy_clip,\n",
    "                        1+self.policy_clip)*advantage[batch]\n",
    "                actor_loss = -T.min(weighted_probs, weighted_clipped_probs).mean()\n",
    "\n",
    "                returns = advantage[batch] + values[batch]\n",
    "                critic_loss = (returns-critic_value)**2\n",
    "                critic_loss = critic_loss.mean()\n",
    "\n",
    "                total_loss = actor_loss + 0.5*critic_loss\n",
    "                self.actor.optimizer.zero_grad()\n",
    "                self.critic.optimizer.zero_grad()\n",
    "                total_loss.backward()\n",
    "                self.actor.optimizer.step()\n",
    "                self.critic.optimizer.step()\n",
    "\n",
    "        self.memory.clear_memory()               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "225de5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(x, scores, figure_file):\n",
    "    running_avg = np.zeros(len(scores))\n",
    "    for i in range(len(running_avg)):\n",
    "        running_avg[i] = np.mean(scores[max(0, i-100):(i+1)])\n",
    "    plt.plot(x, running_avg)\n",
    "    plt.title('Running average of previous 100 scores')\n",
    "    #plt.savefig(figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40a4b740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9a0b29cacd45b793a7725108d9111a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... saving models ...\n",
      "episode 0 score 9302.8 avg score 9302.8 time_steps 720 learning_steps 36\n",
      "... saving models ...\n",
      "episode 1 score 20225.5 avg score 14764.2 time_steps 1440 learning_steps 72\n",
      "... saving models ...\n",
      "episode 2 score 21375.1 avg score 16967.8 time_steps 2160 learning_steps 108\n",
      "... saving models ...\n",
      "episode 3 score 23371.7 avg score 18568.8 time_steps 2880 learning_steps 144\n",
      "... saving models ...\n",
      "episode 4 score 23321.8 avg score 19519.4 time_steps 3600 learning_steps 180\n",
      "... saving models ...\n",
      "episode 5 score 21841.9 avg score 19906.5 time_steps 4320 learning_steps 216\n",
      "episode 6 score 19464.1 avg score 19843.3 time_steps 5040 learning_steps 252\n",
      "... saving models ...\n",
      "episode 7 score 21936.4 avg score 20104.9 time_steps 5760 learning_steps 288\n",
      "... saving models ...\n",
      "episode 8 score 22444.7 avg score 20364.9 time_steps 6480 learning_steps 324\n",
      "... saving models ...\n",
      "episode 9 score 26437.6 avg score 20972.2 time_steps 7200 learning_steps 360\n",
      "episode 10 score 16587.7 avg score 20573.6 time_steps 7920 learning_steps 396\n",
      "episode 11 score 22058.8 avg score 20697.3 time_steps 8640 learning_steps 432\n",
      "episode 12 score 22670.0 avg score 20849.1 time_steps 9360 learning_steps 468\n",
      "episode 13 score 20789.7 avg score 20844.9 time_steps 10080 learning_steps 504\n",
      "episode 14 score 18707.0 avg score 20702.3 time_steps 10800 learning_steps 540\n",
      "episode 15 score 22410.1 avg score 20809.1 time_steps 11520 learning_steps 576\n",
      "... saving models ...\n",
      "episode 16 score 24615.4 avg score 21033.0 time_steps 12240 learning_steps 612\n",
      "... saving models ...\n",
      "episode 17 score 24191.1 avg score 21208.4 time_steps 12960 learning_steps 648\n",
      "... saving models ...\n",
      "episode 18 score 24489.8 avg score 21381.1 time_steps 13680 learning_steps 684\n",
      "... saving models ...\n",
      "episode 19 score 23153.1 avg score 21469.7 time_steps 14400 learning_steps 720\n",
      "episode 20 score 1384.3 avg score 20513.3 time_steps 15120 learning_steps 756\n",
      "episode 21 score 20552.5 avg score 20515.0 time_steps 15840 learning_steps 792\n",
      "episode 22 score 21101.7 avg score 20540.6 time_steps 16560 learning_steps 828\n",
      "episode 23 score 24311.0 avg score 20697.7 time_steps 17280 learning_steps 864\n",
      "episode 24 score 21188.4 avg score 20717.3 time_steps 18000 learning_steps 900\n",
      "episode 25 score 19886.7 avg score 20685.3 time_steps 18720 learning_steps 936\n",
      "episode 26 score 27533.8 avg score 20939.0 time_steps 19440 learning_steps 972\n",
      "episode 27 score 25293.0 avg score 21094.5 time_steps 20160 learning_steps 1008\n",
      "episode 28 score 25506.1 avg score 21246.6 time_steps 20880 learning_steps 1044\n",
      "episode 29 score 24528.3 avg score 21356.0 time_steps 21600 learning_steps 1080\n",
      "episode 30 score 24178.1 avg score 21447.0 time_steps 22320 learning_steps 1116\n",
      "... saving models ...\n",
      "episode 31 score 23330.4 avg score 21505.9 time_steps 23040 learning_steps 1152\n",
      "... saving models ...\n",
      "episode 32 score 27069.5 avg score 21674.5 time_steps 23760 learning_steps 1188\n",
      "... saving models ...\n",
      "episode 33 score 22846.2 avg score 21709.0 time_steps 24480 learning_steps 1224\n",
      "episode 34 score 21113.3 avg score 21691.9 time_steps 25200 learning_steps 1260\n",
      "... saving models ...\n",
      "episode 35 score 25347.6 avg score 21793.5 time_steps 25920 learning_steps 1296\n",
      "... saving models ...\n",
      "episode 36 score 23999.4 avg score 21853.1 time_steps 26640 learning_steps 1332\n",
      "... saving models ...\n",
      "episode 37 score 25391.1 avg score 21946.2 time_steps 27360 learning_steps 1368\n",
      "episode 38 score 17928.8 avg score 21843.2 time_steps 28080 learning_steps 1404\n",
      "episode 39 score 20832.7 avg score 21817.9 time_steps 28800 learning_steps 1440\n",
      "episode 40 score 20202.7 avg score 21778.5 time_steps 29520 learning_steps 1476\n",
      "episode 41 score 14716.3 avg score 21610.4 time_steps 30240 learning_steps 1512\n",
      "episode 42 score 26118.2 avg score 21715.2 time_steps 30960 learning_steps 1548\n",
      "episode 43 score 23653.5 avg score 21759.3 time_steps 31680 learning_steps 1584\n",
      "episode 44 score 19192.3 avg score 21702.2 time_steps 32400 learning_steps 1620\n",
      "episode 45 score 24527.4 avg score 21763.6 time_steps 33120 learning_steps 1656\n",
      "episode 46 score 11001.7 avg score 21534.7 time_steps 33840 learning_steps 1692\n",
      "episode 47 score 26693.5 avg score 21642.1 time_steps 34560 learning_steps 1728\n",
      "episode 48 score 22948.9 avg score 21668.8 time_steps 35280 learning_steps 1764\n",
      "episode 49 score 20669.0 avg score 21648.8 time_steps 36000 learning_steps 1800\n",
      "... saving models ...\n"
     ]
    },
    {
     "data": {
      "application/pdf": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"411.605156pt\" height=\"314.807469pt\" viewBox=\"0 0 411.605156 314.807469\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-05-09T16:54:37.180119</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.10.3, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 314.807469 \n",
       "L 411.605156 314.807469 \n",
       "L 411.605156 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 47.285156 288.047625 \n",
       "L 404.405156 288.047625 \n",
       "L 404.405156 21.935625 \n",
       "L 47.285156 21.935625 \n",
       "z\n",
       "\" style=\"fill: #eaeaf2\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 56.892281 288.047625 \n",
       "L 56.892281 21.935625 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(53.833765 305.421219) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path d=\"M 123.14831 288.047625 \n",
       "L 123.14831 21.935625 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 10 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(117.031279 305.421219) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 189.40434 288.047625 \n",
       "L 189.40434 21.935625 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 20 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(183.287309 305.421219) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path d=\"M 255.66037 288.047625 \n",
       "L 255.66037 21.935625 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 30 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(249.543338 305.421219) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-33\" d=\"M 269 1209 \n",
       "L 831 1284 \n",
       "Q 928 806 1161 595 \n",
       "Q 1394 384 1728 384 \n",
       "Q 2125 384 2398 659 \n",
       "Q 2672 934 2672 1341 \n",
       "Q 2672 1728 2419 1979 \n",
       "Q 2166 2231 1775 2231 \n",
       "Q 1616 2231 1378 2169 \n",
       "L 1441 2663 \n",
       "Q 1497 2656 1531 2656 \n",
       "Q 1891 2656 2178 2843 \n",
       "Q 2466 3031 2466 3422 \n",
       "Q 2466 3731 2256 3934 \n",
       "Q 2047 4138 1716 4138 \n",
       "Q 1388 4138 1169 3931 \n",
       "Q 950 3725 888 3313 \n",
       "L 325 3413 \n",
       "Q 428 3978 793 4289 \n",
       "Q 1159 4600 1703 4600 \n",
       "Q 2078 4600 2393 4439 \n",
       "Q 2709 4278 2876 4000 \n",
       "Q 3044 3722 3044 3409 \n",
       "Q 3044 3113 2884 2869 \n",
       "Q 2725 2625 2413 2481 \n",
       "Q 2819 2388 3044 2092 \n",
       "Q 3269 1797 3269 1353 \n",
       "Q 3269 753 2831 336 \n",
       "Q 2394 -81 1725 -81 \n",
       "Q 1122 -81 723 278 \n",
       "Q 325 638 269 1209 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 321.916399 288.047625 \n",
       "L 321.916399 21.935625 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 40 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(315.799368 305.421219) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path d=\"M 388.172429 288.047625 \n",
       "L 388.172429 21.935625 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 50 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(382.055398 305.421219) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
       "L 856 1250 \n",
       "Q 922 819 1161 601 \n",
       "Q 1400 384 1738 384 \n",
       "Q 2144 384 2425 690 \n",
       "Q 2706 997 2706 1503 \n",
       "Q 2706 1984 2436 2262 \n",
       "Q 2166 2541 1728 2541 \n",
       "Q 1456 2541 1237 2417 \n",
       "Q 1019 2294 894 2097 \n",
       "L 366 2166 \n",
       "L 809 4519 \n",
       "L 3088 4519 \n",
       "L 3088 3981 \n",
       "L 1259 3981 \n",
       "L 1013 2750 \n",
       "Q 1425 3038 1878 3038 \n",
       "Q 2478 3038 2890 2622 \n",
       "Q 3303 2206 3303 1553 \n",
       "Q 3303 931 2941 478 \n",
       "Q 2500 -78 1738 -78 \n",
       "Q 1113 -78 717 272 \n",
       "Q 322 622 266 1200 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 47.285156 262.612089 \n",
       "L 404.405156 262.612089 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 10000 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 266.548886) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path d=\"M 47.285156 224.343793 \n",
       "L 404.405156 224.343793 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 12000 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 228.28059) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 47.285156 186.075497 \n",
       "L 404.405156 186.075497 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 14000 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 190.012294) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path d=\"M 47.285156 147.807201 \n",
       "L 404.405156 147.807201 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 16000 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 151.743998) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-36\" d=\"M 3184 3459 \n",
       "L 2625 3416 \n",
       "Q 2550 3747 2413 3897 \n",
       "Q 2184 4138 1850 4138 \n",
       "Q 1581 4138 1378 3988 \n",
       "Q 1113 3794 959 3422 \n",
       "Q 806 3050 800 2363 \n",
       "Q 1003 2672 1297 2822 \n",
       "Q 1591 2972 1913 2972 \n",
       "Q 2475 2972 2870 2558 \n",
       "Q 3266 2144 3266 1488 \n",
       "Q 3266 1056 3080 686 \n",
       "Q 2894 316 2569 119 \n",
       "Q 2244 -78 1831 -78 \n",
       "Q 1128 -78 684 439 \n",
       "Q 241 956 241 2144 \n",
       "Q 241 3472 731 4075 \n",
       "Q 1159 4600 1884 4600 \n",
       "Q 2425 4600 2770 4297 \n",
       "Q 3116 3994 3184 3459 \n",
       "z\n",
       "M 888 1484 \n",
       "Q 888 1194 1011 928 \n",
       "Q 1134 663 1356 523 \n",
       "Q 1578 384 1822 384 \n",
       "Q 2178 384 2434 671 \n",
       "Q 2691 959 2691 1453 \n",
       "Q 2691 1928 2437 2201 \n",
       "Q 2184 2475 1800 2475 \n",
       "Q 1419 2475 1153 2201 \n",
       "Q 888 1928 888 1484 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 47.285156 109.538905 \n",
       "L 404.405156 109.538905 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 18000 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 113.475702) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-38\" d=\"M 1131 2484 \n",
       "Q 781 2613 612 2850 \n",
       "Q 444 3088 444 3419 \n",
       "Q 444 3919 803 4259 \n",
       "Q 1163 4600 1759 4600 \n",
       "Q 2359 4600 2725 4251 \n",
       "Q 3091 3903 3091 3403 \n",
       "Q 3091 3084 2923 2848 \n",
       "Q 2756 2613 2416 2484 \n",
       "Q 2838 2347 3058 2040 \n",
       "Q 3278 1734 3278 1309 \n",
       "Q 3278 722 2862 322 \n",
       "Q 2447 -78 1769 -78 \n",
       "Q 1091 -78 675 323 \n",
       "Q 259 725 259 1325 \n",
       "Q 259 1772 486 2073 \n",
       "Q 713 2375 1131 2484 \n",
       "z\n",
       "M 1019 3438 \n",
       "Q 1019 3113 1228 2906 \n",
       "Q 1438 2700 1772 2700 \n",
       "Q 2097 2700 2305 2904 \n",
       "Q 2513 3109 2513 3406 \n",
       "Q 2513 3716 2298 3927 \n",
       "Q 2084 4138 1766 4138 \n",
       "Q 1444 4138 1231 3931 \n",
       "Q 1019 3725 1019 3438 \n",
       "z\n",
       "M 838 1322 \n",
       "Q 838 1081 952 856 \n",
       "Q 1066 631 1291 507 \n",
       "Q 1516 384 1775 384 \n",
       "Q 2178 384 2440 643 \n",
       "Q 2703 903 2703 1303 \n",
       "Q 2703 1709 2433 1975 \n",
       "Q 2163 2241 1756 2241 \n",
       "Q 1359 2241 1098 1978 \n",
       "Q 838 1716 838 1322 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-38\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <path d=\"M 47.285156 71.270609 \n",
       "L 404.405156 71.270609 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 20000 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 75.207406) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 47.285156 33.002314 \n",
       "L 404.405156 33.002314 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 22000 -->\n",
       "      <g style=\"fill: #262626\" transform=\"translate(7.2 36.93911) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 63.517884 275.951625 \n",
       "L 70.143486 171.45411 \n",
       "L 76.769089 129.288877 \n",
       "L 83.394692 98.65563 \n",
       "L 90.020295 80.466599 \n",
       "L 96.645898 73.06016 \n",
       "L 103.271501 74.269263 \n",
       "L 109.897104 69.263016 \n",
       "L 116.522707 64.288629 \n",
       "L 123.14831 52.669013 \n",
       "L 129.773913 60.295613 \n",
       "L 136.399516 57.927425 \n",
       "L 143.025119 55.023941 \n",
       "L 149.650722 55.1051 \n",
       "L 156.276325 57.832172 \n",
       "L 162.901928 55.789914 \n",
       "L 169.527531 51.505782 \n",
       "L 176.153134 48.148688 \n",
       "L 182.778737 44.844134 \n",
       "L 189.40434 43.148837 \n",
       "L 196.029943 61.449687 \n",
       "L 202.655546 61.415582 \n",
       "L 209.281149 60.927523 \n",
       "L 215.906752 57.92153 \n",
       "L 222.532355 57.545952 \n",
       "L 229.157958 58.157216 \n",
       "L 235.783561 53.303884 \n",
       "L 242.409164 50.328496 \n",
       "L 249.034767 47.41769 \n",
       "L 255.66037 45.324594 \n",
       "L 262.285973 43.582731 \n",
       "L 268.911576 42.456569 \n",
       "L 275.537179 39.230692 \n",
       "L 282.162781 38.571283 \n",
       "L 288.788384 38.89691 \n",
       "L 295.413987 36.953925 \n",
       "L 302.03959 35.813137 \n",
       "L 308.665193 34.031625 \n",
       "L 315.290796 36.002621 \n",
       "L 321.916399 36.486003 \n",
       "L 328.542002 37.239816 \n",
       "L 335.167605 40.457215 \n",
       "L 341.793208 38.451343 \n",
       "L 348.418811 37.608428 \n",
       "L 355.044414 38.699929 \n",
       "L 361.670017 37.524785 \n",
       "L 368.29562 41.906092 \n",
       "L 374.921223 39.849648 \n",
       "L 381.546826 39.339378 \n",
       "L 388.172429 39.721991 \n",
       "\" clip-path=\"url(#p7c66131984)\" style=\"fill: none; stroke: #4c72b0; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 47.285156 288.047625 \n",
       "L 47.285156 21.935625 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 404.405156 288.047625 \n",
       "L 404.405156 21.935625 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 47.285156 288.047625 \n",
       "L 404.405156 288.047625 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 47.285156 21.935625 \n",
       "L 404.405156 21.935625 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-width: 1.25; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_14\">\n",
       "    <!-- Running average of previous 100 scores -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(118.119844 15.935625) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-52\" d=\"M 503 0 \n",
       "L 503 4581 \n",
       "L 2534 4581 \n",
       "Q 3147 4581 3465 4457 \n",
       "Q 3784 4334 3975 4021 \n",
       "Q 4166 3709 4166 3331 \n",
       "Q 4166 2844 3850 2509 \n",
       "Q 3534 2175 2875 2084 \n",
       "Q 3116 1969 3241 1856 \n",
       "Q 3506 1613 3744 1247 \n",
       "L 4541 0 \n",
       "L 3778 0 \n",
       "L 3172 953 \n",
       "Q 2906 1366 2734 1584 \n",
       "Q 2563 1803 2427 1890 \n",
       "Q 2291 1978 2150 2013 \n",
       "Q 2047 2034 1813 2034 \n",
       "L 1109 2034 \n",
       "L 1109 0 \n",
       "L 503 0 \n",
       "z\n",
       "M 1109 2559 \n",
       "L 2413 2559 \n",
       "Q 2828 2559 3062 2645 \n",
       "Q 3297 2731 3419 2920 \n",
       "Q 3541 3109 3541 3331 \n",
       "Q 3541 3656 3305 3865 \n",
       "Q 3069 4075 2559 4075 \n",
       "L 1109 4075 \n",
       "L 1109 2559 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-75\" d=\"M 2597 0 \n",
       "L 2597 488 \n",
       "Q 2209 -75 1544 -75 \n",
       "Q 1250 -75 995 37 \n",
       "Q 741 150 617 320 \n",
       "Q 494 491 444 738 \n",
       "Q 409 903 409 1263 \n",
       "L 409 3319 \n",
       "L 972 3319 \n",
       "L 972 1478 \n",
       "Q 972 1038 1006 884 \n",
       "Q 1059 663 1231 536 \n",
       "Q 1403 409 1656 409 \n",
       "Q 1909 409 2131 539 \n",
       "Q 2353 669 2445 892 \n",
       "Q 2538 1116 2538 1541 \n",
       "L 2538 3319 \n",
       "L 3100 3319 \n",
       "L 3100 0 \n",
       "L 2597 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-6e\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 928 3319 \n",
       "L 928 2847 \n",
       "Q 1294 3394 1984 3394 \n",
       "Q 2284 3394 2536 3286 \n",
       "Q 2788 3178 2913 3003 \n",
       "Q 3038 2828 3088 2588 \n",
       "Q 3119 2431 3119 2041 \n",
       "L 3119 0 \n",
       "L 2556 0 \n",
       "L 2556 2019 \n",
       "Q 2556 2363 2490 2533 \n",
       "Q 2425 2703 2258 2804 \n",
       "Q 2091 2906 1866 2906 \n",
       "Q 1506 2906 1245 2678 \n",
       "Q 984 2450 984 1813 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-69\" d=\"M 425 3934 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 3934 \n",
       "L 425 3934 \n",
       "z\n",
       "M 425 0 \n",
       "L 425 3319 \n",
       "L 988 3319 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-67\" d=\"M 319 -275 \n",
       "L 866 -356 \n",
       "Q 900 -609 1056 -725 \n",
       "Q 1266 -881 1628 -881 \n",
       "Q 2019 -881 2231 -725 \n",
       "Q 2444 -569 2519 -288 \n",
       "Q 2563 -116 2559 434 \n",
       "Q 2191 0 1641 0 \n",
       "Q 956 0 581 494 \n",
       "Q 206 988 206 1678 \n",
       "Q 206 2153 378 2554 \n",
       "Q 550 2956 876 3175 \n",
       "Q 1203 3394 1644 3394 \n",
       "Q 2231 3394 2613 2919 \n",
       "L 2613 3319 \n",
       "L 3131 3319 \n",
       "L 3131 450 \n",
       "Q 3131 -325 2973 -648 \n",
       "Q 2816 -972 2473 -1159 \n",
       "Q 2131 -1347 1631 -1347 \n",
       "Q 1038 -1347 672 -1080 \n",
       "Q 306 -813 319 -275 \n",
       "z\n",
       "M 784 1719 \n",
       "Q 784 1066 1043 766 \n",
       "Q 1303 466 1694 466 \n",
       "Q 2081 466 2343 764 \n",
       "Q 2606 1063 2606 1700 \n",
       "Q 2606 2309 2336 2618 \n",
       "Q 2066 2928 1684 2928 \n",
       "Q 1309 2928 1046 2623 \n",
       "Q 784 2319 784 1719 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
       "Q 2275 144 1986 34 \n",
       "Q 1697 -75 1366 -75 \n",
       "Q 819 -75 525 192 \n",
       "Q 231 459 231 875 \n",
       "Q 231 1119 342 1320 \n",
       "Q 453 1522 633 1644 \n",
       "Q 813 1766 1038 1828 \n",
       "Q 1203 1872 1538 1913 \n",
       "Q 2219 1994 2541 2106 \n",
       "Q 2544 2222 2544 2253 \n",
       "Q 2544 2597 2384 2738 \n",
       "Q 2169 2928 1744 2928 \n",
       "Q 1347 2928 1158 2789 \n",
       "Q 969 2650 878 2297 \n",
       "L 328 2372 \n",
       "Q 403 2725 575 2942 \n",
       "Q 747 3159 1072 3276 \n",
       "Q 1397 3394 1825 3394 \n",
       "Q 2250 3394 2515 3294 \n",
       "Q 2781 3194 2906 3042 \n",
       "Q 3031 2891 3081 2659 \n",
       "Q 3109 2516 3109 2141 \n",
       "L 3109 1391 \n",
       "Q 3109 606 3145 398 \n",
       "Q 3181 191 3288 0 \n",
       "L 2700 0 \n",
       "Q 2613 175 2588 409 \n",
       "z\n",
       "M 2541 1666 \n",
       "Q 2234 1541 1622 1453 \n",
       "Q 1275 1403 1131 1340 \n",
       "Q 988 1278 909 1158 \n",
       "Q 831 1038 831 891 \n",
       "Q 831 666 1001 516 \n",
       "Q 1172 366 1500 366 \n",
       "Q 1825 366 2078 508 \n",
       "Q 2331 650 2450 897 \n",
       "Q 2541 1088 2541 1459 \n",
       "L 2541 1666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-76\" d=\"M 1344 0 \n",
       "L 81 3319 \n",
       "L 675 3319 \n",
       "L 1388 1331 \n",
       "Q 1503 1009 1600 663 \n",
       "Q 1675 925 1809 1294 \n",
       "L 2547 3319 \n",
       "L 3125 3319 \n",
       "L 1869 0 \n",
       "L 1344 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
       "L 3275 997 \n",
       "Q 3138 488 2766 206 \n",
       "Q 2394 -75 1816 -75 \n",
       "Q 1088 -75 661 373 \n",
       "Q 234 822 234 1631 \n",
       "Q 234 2469 665 2931 \n",
       "Q 1097 3394 1784 3394 \n",
       "Q 2450 3394 2872 2941 \n",
       "Q 3294 2488 3294 1666 \n",
       "Q 3294 1616 3291 1516 \n",
       "L 816 1516 \n",
       "Q 847 969 1125 678 \n",
       "Q 1403 388 1819 388 \n",
       "Q 2128 388 2347 550 \n",
       "Q 2566 713 2694 1069 \n",
       "z\n",
       "M 847 1978 \n",
       "L 2700 1978 \n",
       "Q 2663 2397 2488 2606 \n",
       "Q 2219 2931 1791 2931 \n",
       "Q 1403 2931 1139 2672 \n",
       "Q 875 2413 847 1978 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-72\" d=\"M 416 0 \n",
       "L 416 3319 \n",
       "L 922 3319 \n",
       "L 922 2816 \n",
       "Q 1116 3169 1280 3281 \n",
       "Q 1444 3394 1641 3394 \n",
       "Q 1925 3394 2219 3213 \n",
       "L 2025 2691 \n",
       "Q 1819 2813 1613 2813 \n",
       "Q 1428 2813 1281 2702 \n",
       "Q 1134 2591 1072 2394 \n",
       "Q 978 2094 978 1738 \n",
       "L 978 0 \n",
       "L 416 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-6f\" d=\"M 213 1659 \n",
       "Q 213 2581 725 3025 \n",
       "Q 1153 3394 1769 3394 \n",
       "Q 2453 3394 2887 2945 \n",
       "Q 3322 2497 3322 1706 \n",
       "Q 3322 1066 3130 698 \n",
       "Q 2938 331 2570 128 \n",
       "Q 2203 -75 1769 -75 \n",
       "Q 1072 -75 642 372 \n",
       "Q 213 819 213 1659 \n",
       "z\n",
       "M 791 1659 \n",
       "Q 791 1022 1069 705 \n",
       "Q 1347 388 1769 388 \n",
       "Q 2188 388 2466 706 \n",
       "Q 2744 1025 2744 1678 \n",
       "Q 2744 2294 2464 2611 \n",
       "Q 2184 2928 1769 2928 \n",
       "Q 1347 2928 1069 2612 \n",
       "Q 791 2297 791 1659 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-66\" d=\"M 556 0 \n",
       "L 556 2881 \n",
       "L 59 2881 \n",
       "L 59 3319 \n",
       "L 556 3319 \n",
       "L 556 3672 \n",
       "Q 556 4006 616 4169 \n",
       "Q 697 4388 901 4523 \n",
       "Q 1106 4659 1475 4659 \n",
       "Q 1713 4659 2000 4603 \n",
       "L 1916 4113 \n",
       "Q 1741 4144 1584 4144 \n",
       "Q 1328 4144 1222 4034 \n",
       "Q 1116 3925 1116 3625 \n",
       "L 1116 3319 \n",
       "L 1763 3319 \n",
       "L 1763 2881 \n",
       "L 1116 2881 \n",
       "L 1116 0 \n",
       "L 556 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-70\" d=\"M 422 -1272 \n",
       "L 422 3319 \n",
       "L 934 3319 \n",
       "L 934 2888 \n",
       "Q 1116 3141 1344 3267 \n",
       "Q 1572 3394 1897 3394 \n",
       "Q 2322 3394 2647 3175 \n",
       "Q 2972 2956 3137 2557 \n",
       "Q 3303 2159 3303 1684 \n",
       "Q 3303 1175 3120 767 \n",
       "Q 2938 359 2589 142 \n",
       "Q 2241 -75 1856 -75 \n",
       "Q 1575 -75 1351 44 \n",
       "Q 1128 163 984 344 \n",
       "L 984 -1272 \n",
       "L 422 -1272 \n",
       "z\n",
       "M 931 1641 \n",
       "Q 931 1000 1190 694 \n",
       "Q 1450 388 1819 388 \n",
       "Q 2194 388 2461 705 \n",
       "Q 2728 1022 2728 1688 \n",
       "Q 2728 2322 2467 2637 \n",
       "Q 2206 2953 1844 2953 \n",
       "Q 1484 2953 1207 2617 \n",
       "Q 931 2281 931 1641 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-73\" d=\"M 197 991 \n",
       "L 753 1078 \n",
       "Q 800 744 1014 566 \n",
       "Q 1228 388 1613 388 \n",
       "Q 2000 388 2187 545 \n",
       "Q 2375 703 2375 916 \n",
       "Q 2375 1106 2209 1216 \n",
       "Q 2094 1291 1634 1406 \n",
       "Q 1016 1563 777 1677 \n",
       "Q 538 1791 414 1992 \n",
       "Q 291 2194 291 2438 \n",
       "Q 291 2659 392 2848 \n",
       "Q 494 3038 669 3163 \n",
       "Q 800 3259 1026 3326 \n",
       "Q 1253 3394 1513 3394 \n",
       "Q 1903 3394 2198 3281 \n",
       "Q 2494 3169 2634 2976 \n",
       "Q 2775 2784 2828 2463 \n",
       "L 2278 2388 \n",
       "Q 2241 2644 2061 2787 \n",
       "Q 1881 2931 1553 2931 \n",
       "Q 1166 2931 1000 2803 \n",
       "Q 834 2675 834 2503 \n",
       "Q 834 2394 903 2306 \n",
       "Q 972 2216 1119 2156 \n",
       "Q 1203 2125 1616 2013 \n",
       "Q 2213 1853 2448 1751 \n",
       "Q 2684 1650 2818 1456 \n",
       "Q 2953 1263 2953 975 \n",
       "Q 2953 694 2789 445 \n",
       "Q 2625 197 2315 61 \n",
       "Q 2006 -75 1616 -75 \n",
       "Q 969 -75 630 194 \n",
       "Q 291 463 197 991 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-63\" d=\"M 2588 1216 \n",
       "L 3141 1144 \n",
       "Q 3050 572 2676 248 \n",
       "Q 2303 -75 1759 -75 \n",
       "Q 1078 -75 664 370 \n",
       "Q 250 816 250 1647 \n",
       "Q 250 2184 428 2587 \n",
       "Q 606 2991 970 3192 \n",
       "Q 1334 3394 1763 3394 \n",
       "Q 2303 3394 2647 3120 \n",
       "Q 2991 2847 3088 2344 \n",
       "L 2541 2259 \n",
       "Q 2463 2594 2264 2762 \n",
       "Q 2066 2931 1784 2931 \n",
       "Q 1359 2931 1093 2626 \n",
       "Q 828 2322 828 1663 \n",
       "Q 828 994 1084 691 \n",
       "Q 1341 388 1753 388 \n",
       "Q 2084 388 2306 591 \n",
       "Q 2528 794 2588 1216 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-52\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(72.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(127.832031 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(183.447266 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(239.0625 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(261.279297 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-67\" transform=\"translate(316.894531 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(372.509766 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" transform=\"translate(400.292969 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-76\" transform=\"translate(455.908203 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(505.908203 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(561.523438 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" transform=\"translate(594.824219 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-67\" transform=\"translate(650.439453 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(706.054688 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(761.669922 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(789.453125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-66\" transform=\"translate(845.068359 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(872.851562 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-70\" transform=\"translate(900.634766 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(956.25 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(989.550781 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-76\" transform=\"translate(1045.166016 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(1095.166016 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(1117.382812 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(1172.998047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(1228.613281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(1278.613281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-31\" transform=\"translate(1306.396484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-30\" transform=\"translate(1362.011719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-30\" transform=\"translate(1417.626953 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(1473.242188 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(1501.025391 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(1551.025391 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(1601.025391 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(1656.640625 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(1689.941406 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(1745.556641 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p7c66131984\">\n",
       "   <rect x=\"47.285156\" y=\"21.935625\" width=\"357.12\" height=\"266.112\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "    T.manual_seed(seed)\n",
    "    T.cuda.manual_seed(seed)\n",
    "    T.cuda.manual_seed_all(seed)\n",
    "    env = BS_EV()\n",
    "    # kettle, rice cooker, dish washer, washing machine\n",
    "    N = 20\n",
    "    batch_size =16\n",
    "    n_epochs = 4\n",
    "    alpha = 0.0001\n",
    "    agent = Agent(n_actions=env.n_actions, batch_size=batch_size, \n",
    "                    alpha=alpha, n_epochs=n_epochs, \n",
    "                    input_dims=env.n_states)\n",
    "    n_games = 50\n",
    "\n",
    "    figure_file = 'figure/learning_curve_PPO.png'\n",
    "\n",
    "    best_score = float('-inf')\n",
    "    score_history = []\n",
    "\n",
    "    learn_iters = 0\n",
    "    avg_score = 0\n",
    "    n_steps = 0\n",
    "\n",
    "    for i in tqdm(range(n_games)):\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        score = 0\n",
    "        while not done:\n",
    "            #print(env.T)\n",
    "            action, prob, val = agent.choose_action(observation)\n",
    "            observation_, reward, done = env.step(action)\n",
    "            n_steps += 1\n",
    "            score += reward\n",
    "            agent.remember(observation, action, prob, val, reward, done)\n",
    "            if n_steps % N == 0:\n",
    "                agent.learn()\n",
    "                learn_iters += 1\n",
    "            observation = observation_\n",
    "        score_history.append(score)\n",
    "        avg_score = np.mean(score_history[-100:])\n",
    "\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            agent.save_models_best()\n",
    "\n",
    "        print('episode', i, 'score %.1f' % score, 'avg score %.1f' % avg_score,\n",
    "                'time_steps', n_steps, 'learning_steps', learn_iters)\n",
    "    agent.save_models_last()\n",
    "    x = [i+1 for i in range(len(score_history))]\n",
    "    plot_learning_curve(x, score_history, figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb8b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
